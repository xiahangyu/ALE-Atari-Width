{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class layer():\n",
    "\n",
    "    #Inputs: \n",
    "    #   screens : tensor, [None, 33600]\n",
    "    #Outputs:\n",
    "    #   encode : tensor, [None, 1024]\n",
    "    #   cnn_shapes : python list, shapes of each convolution layers\n",
    "    def conv_encoder(screens):\n",
    "        screens = tf.reshape(screens, [-1, 210, 160, 1])\n",
    "\n",
    "        cnn_shapes = []\n",
    "        with tf.variable_scope(\"training\"):\n",
    "            with tf.variable_scope(\"cnn_layers\", reuse=tf.AUTO_REUSE):\n",
    "                cnn_shapes.append(screens.get_shape().as_list())\n",
    "                w1 = tf.get_variable(\"conv1_weights\", [4, 4, 1, 64], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                conv1 = tf.nn.relu(tf.nn.conv2d(screens, w1, strides=[1, 2, 2, 1], padding='SAME'))\n",
    "                cnn_shapes.append(conv1.get_shape().as_list())\n",
    "\n",
    "                w2 = tf.get_variable(\"conv2_weights\", [6, 6, 64, 128], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                conv2 = tf.nn.relu(tf.nn.conv2d(conv1, w2, strides=[1, 2, 2, 1], padding='SAME'))\n",
    "                cnn_shapes.append(conv2.get_shape().as_list())\n",
    "\n",
    "                w3 = tf.get_variable(\"conv3_weights\", [6, 6, 128, 128], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                conv3 = tf.nn.relu(tf.nn.conv2d(conv2, w3, strides=[1, 2, 2, 1], padding='SAME'))\n",
    "                cnn_shapes.append(conv3.get_shape().as_list())\n",
    "\n",
    "                w4 = tf.get_variable(\"conv4_weights\", [8, 8, 128, 128], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                conv4 = tf.nn.relu(tf.nn.conv2d(conv3, w4, strides=[1, 2, 2, 1], padding='SAME'))\n",
    "                cnn_shapes.append(conv4.get_shape().as_list())\n",
    "            with tf.variable_scope(\"flatten_layers\", reuse=tf.AUTO_REUSE):\n",
    "                flatten = tf.contrib.layers.flatten(inputs = conv4)\n",
    "\n",
    "                # w51 = tf.get_variable(\"dense1_weights\", [27*20*8, 4096], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                # b51 = tf.get_variable(\"dense1_bias\", [4096], initializer=tf.zeros_initializer())\n",
    "                # encode1 = tf.matmul(flatten, w51) + b51\n",
    "\n",
    "                # w52 = tf.get_variable(\"dense2_weights\", [4096, 2048], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                # b52 = tf.get_variable(\"dense2_bias\", [2048], initializer=tf.zeros_initializer())\n",
    "                # encode2 = tf.nn.relu(tf.matmul(encode1, w52) + b52)\n",
    "        return flatten, cnn_shapes\n",
    "\n",
    "\n",
    "    #Inputs:\n",
    "    #   pred_encode : tensor, [None, 1024]\n",
    "    #   cnn_shapes : python list, shapes of each convolution layers\n",
    "    #Outputs:\n",
    "    #   decode : tensor, [None, 33600]\n",
    "    def conv_decoder(pred_encode, cnn_shapes):\n",
    "        with tf.variable_scope(\"training\"):\n",
    "            with tf.variable_scope(\"dense_layers\", reuse=tf.AUTO_REUSE):\n",
    "                # w01 = tf.get_variable(\"dense1_weights\", [2048, 4096], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                # b01 = tf.get_variable(\"dense1_bias\", [4096], initializer=tf.zeros_initializer())\n",
    "                # dense1 = tf.matmul(pred_encode, w01) + b01\n",
    "\n",
    "                # w02 = tf.get_variable(\"dense2_weights\", [4096, 27*20*8], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                # b02 = tf.get_variable(\"dense2_bias\", [27*20*8], initializer=tf.zeros_initializer())\n",
    "                # dense2 = tf.nn.relu(tf.matmul(dense1, w02) + b02)\n",
    "\n",
    "                conv_trans_input = tf.reshape(pred_encode, tf.stack([tf.shape(pred_encode)[0], cnn_shapes[4][1], cnn_shapes[4][2], cnn_shapes[4][3]]))\n",
    "\n",
    "            with tf.variable_scope(\"cnn_layers\", reuse=tf.AUTO_REUSE):\n",
    "                w1 = tf.get_variable(\"conv4_weights\", [8, 8, 128, 128], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                conv_transpose1 = tf.nn.relu(tf.nn.conv2d_transpose(conv_trans_input, w1,\n",
    "                                                                    tf.stack([tf.shape(pred_encode)[0], cnn_shapes[3][1], cnn_shapes[3][2], cnn_shapes[3][3]]),\n",
    "                                                                    strides=[1, 2, 2, 1], padding='SAME'))\n",
    "\n",
    "                w2 = tf.get_variable(\"conv_trans2_weights\", [6, 6, 128, 128], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                conv_transpose2 = tf.nn.relu(tf.nn.conv2d_transpose(conv_transpose1, w2,\n",
    "                                                                    tf.stack([tf.shape(pred_encode)[0], cnn_shapes[2][1], cnn_shapes[2][2], cnn_shapes[2][3]]),\n",
    "                                                                    strides=[1, 2, 2, 1],padding='SAME'))\n",
    "\n",
    "                w3 = tf.get_variable(\"conv_trans3_weights\", [6, 6, 64, 128], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                conv_transpose3 = tf.nn.relu(tf.nn.conv2d_transpose(conv_transpose2, w3, \n",
    "                                                                    tf.stack([tf.shape(pred_encode)[0], cnn_shapes[1][1], cnn_shapes[1][2], cnn_shapes[1][3]]), \n",
    "                                                                    strides=[1, 2, 2, 1],padding='SAME'))\n",
    "\n",
    "                w4 = tf.get_variable(\"conv_trans4_weights\", [4, 4, 1, 64], initializer=tf.contrib.layers.xavier_initializer())\n",
    "                conv_transpose4 = tf.nn.relu(tf.nn.conv2d_transpose(conv_transpose3, w4, \n",
    "                                                                 tf.stack([tf.shape(pred_encode)[0], cnn_shapes[0][1], cnn_shapes[0][2], 1]), \n",
    "                                                                 strides=[1, 2, 2, 1],padding='SAME'))\n",
    "\n",
    "        decode = tf.reshape(conv_transpose4, [-1, 33600])\n",
    "        return decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AEModel(object):\n",
    "    def __init__(self) : #, mean_img = np.zeros([1, 33600])\n",
    "        #mean_img = np.reshape(mean_img, newshape=[1, 33600])\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "        self.x = tf.placeholder(tf.float32, [None, 33600], name='x')\n",
    "\n",
    "        #self.mean = tf.Variable(mean_img, trainable=False, dtype=tf.float32)\n",
    "        #self.x_mean = (self.x-self.mean)\n",
    "\n",
    "        self.train_nn()\n",
    "\n",
    "        self.merged = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "    def train_nn(self):\n",
    "        #encode\n",
    "        encode, conv_shapes = layer.conv_encoder(self.x)\n",
    "\n",
    "        #hidden state\n",
    "        #self.hidden = tf.reshape(encode, [-1, 53*40])\n",
    "        self.hidden = tf.cast(tf.round(encode), tf.int32, name = \"hidden\")\n",
    "\n",
    "        #decode\n",
    "        decode = layer.conv_decoder(encode, conv_shapes)\n",
    "        x_hat = decode #+self.mean\n",
    "        self.x_hat = tf.cast(tf.round(x_hat), tf.int32, name=\"x_hat\") \n",
    "\n",
    "        with tf.variable_scope(\"cost\"):\n",
    "            self.cost = tf.reduce_mean(tf.reduce_mean(tf.square(x_hat - self.x), 1),  name=\"cost\") \n",
    "            tf.summary.scalar(\"cost\",self.cost)\n",
    "\n",
    "        with tf.variable_scope(\"optimize\"):\n",
    "            learning_rate = 0.001\n",
    "            #self.optimizer = tf.train.AdamOptimizer(learning_rate, name=\"optimizer\").minimize(self.cost)\n",
    "            self.optimizer = tf.train.RMSPropOptimizer(learning_rate, name=\"optimizer\").minimize(self.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:459: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ae = AEModel()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"./ckpt/model\")\n",
    "\n",
    "screen_dir = \"../../../screens/freeway/subtracted/matrix/\"\n",
    "n_train_screens = 1024\n",
    "train_screens = np.zeros((BATCH_SIZE, 33600))\n",
    "\n",
    "for i in range(0, BATCH_SIZE):\n",
    "    path = screen_dir + str(n_train_screens + i) + \".matrix\"\n",
    "    with open(path, \"r\") as f:\n",
    "        data = f.read().split(' ')\n",
    "        pixels = data[:-1]\n",
    "        pixels = list(map(int, pixels))\n",
    "        train_screens[i] = np.array(pixels)\n",
    "\n",
    "hidden, x_hat = sess.run([ae.hidden, ae.x_hat], feed_dict={ae.x: train_screens})\n",
    "\n",
    "n_examples = 2\n",
    "fig, axs = plt.subplots(n_examples, 2, figsize=(210, 160), squeeze=False)\n",
    "for example_i in range(n_examples):\n",
    "    axs[example_i][0].imshow(\n",
    "        np.reshape(train_screens[0], (210, 160)))\n",
    "    axs[example_i][1].imshow(\n",
    "        np.reshape(x_hat[0], (210, 160)))\n",
    "fig.show()\n",
    "plt.draw()  #plt.show()\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
